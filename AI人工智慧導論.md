閱讀筆記

Source: 人工智慧導論 2019 鴻海教育基金會 
Date: 2025-02
rjsiao

認識AI
-
1. 如何做人工智慧
- 培養觀察力。
- 訓練問問題。
- 聊天機器人用遞歸神經網路納入前一次狀態。
2. 函數f是解答本
- 定義域X：所有可能問題的集合。
- 值域Y：所有可能答案的集合。
3. 如何使用AI解決問題
- (1) 提問。
- (2) 將問題轉換成函數。
- (3) 收集歷史資料，注意過度擬合。70%訓練資料、30%測試資料。
- (4) 以機器學習、神經網路建構函數學習機。
- (5) 學習或訓練機器學習機，建模，注意損失函數。
4. 近期AI大爆發主因及挑戰
- 複雜的軟體、計算能力提升、大數據累積。
- 電腦無法提出好問題，且無法自動建造函數學習機。
5. 常見與機器學習有關的演算法
- 分類：對應監督式學習，將未知新訊息歸納到已知資訊類別，根據多個特徵將分類結果加上標籤，如生物學分類。
- 分群：對應非監督式學習，資料集沒有明確分類，需以特徵區分成不同群集。
- 一般表示方法：2~3個維度用線性分類器，超平面n維度用數學方程式。
6. 監督式學習
- 支持向量機 (SVM)：根據核函數用決定以線性或非線性分類器分群，找出最大支持向量(兩分類間距離分類線最近的點取對大距離)
- 決策樹 (decision tree)：建立多元樹，包括根節點、節點、葉，透過迭代試驗找出一分類原則有較高正確率的資訊獲利。
- K近鄰 (KNN)：k值表示比對k個已分類最接近的資料點，通常為奇數。
7. 非監督式學習
- K平均 (k-means)：隨機分成k個群集，持續迭代計算出每個分群的重心與重新分群。

神經網絡架構
1. 神經網絡原理：以標準NN為例
- 使用時首先決定輸入、輸出的維度。
- 人工神經網絡：輸入層、隱藏層、輸出層。連接神經網絡、前饋神經網絡。
- 決定隱藏層數量，以及每個隱藏層的神經元數量。隱藏層數量大於3層稱為深度學習。
- 損失函數 L 的變數有二：(1)權重數值 wi 越大，輸入的越重要。(2)偏值 bi 用來調整總刺激。
- 激活函數判斷刺激夠大為1，可忽略者0。
- 學習速率 r 
- 梯度 gradient L 與損失函數 L 方向相反。
2. 神經網絡模式
- (1)標準NN | 全連結神經網絡
- (2)卷積CNN：常用於圖形辨識
- (3)遞歸RNN：保有前次輸入記憶
- 身身

